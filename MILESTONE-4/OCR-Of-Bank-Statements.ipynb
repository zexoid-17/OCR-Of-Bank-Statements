{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90111e15-bfb3-4fbf-af34-e63a10d4bd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/12/28 23:13:19] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\DELLL/.paddleocr/whl\\\\det\\\\ch\\\\ch_PP-OCRv4_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\DELLL/.paddleocr/whl\\\\rec\\\\ch\\\\ch_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='C:\\\\Users\\\\DELLL\\\\anaconda3\\\\Lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\ppocr_keys_v1.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir='C:\\\\Users\\\\DELLL/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='ch', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/12/28 23:13:49] ppocr WARNING: Since the angle classifier is not initialized, it will not be used during the forward process\n",
      "[2024/12/28 23:13:50] ppocr DEBUG: dt_boxes num : 37, elapsed : 1.11138916015625\n",
      "[2024/12/28 23:13:53] ppocr DEBUG: rec_res num  : 37, elapsed : 2.6321802139282227\n",
      "[2024/12/28 23:13:56] ppocr WARNING: Since the angle classifier is not initialized, it will not be used during the forward process\n",
      "[2024/12/28 23:13:56] ppocr DEBUG: dt_boxes num : 56, elapsed : 0.5669825077056885\n",
      "[2024/12/28 23:13:59] ppocr DEBUG: rec_res num  : 56, elapsed : 2.852916717529297\n",
      "[2024/12/28 23:14:57] ppocr WARNING: Since the angle classifier is not initialized, it will not be used during the forward process\n",
      "[2024/12/28 23:14:58] ppocr DEBUG: dt_boxes num : 44, elapsed : 0.8498492240905762\n",
      "[2024/12/28 23:15:00] ppocr DEBUG: rec_res num  : 44, elapsed : 2.7937331199645996\n",
      "[2024/12/28 23:15:03] ppocr WARNING: Since the angle classifier is not initialized, it will not be used during the forward process\n",
      "[2024/12/28 23:15:04] ppocr DEBUG: dt_boxes num : 65, elapsed : 1.0078694820404053\n",
      "[2024/12/28 23:15:09] ppocr DEBUG: rec_res num  : 65, elapsed : 4.947551965713501\n",
      "[2024/12/28 23:15:15] ppocr WARNING: Since the angle classifier is not initialized, it will not be used during the forward process\n",
      "[2024/12/28 23:15:15] ppocr DEBUG: dt_boxes num : 37, elapsed : 0.7882885932922363\n",
      "[2024/12/28 23:15:18] ppocr DEBUG: rec_res num  : 37, elapsed : 2.427828788757324\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from paddleocr import PaddleOCR\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cohere\n",
    "import re\n",
    "import gradio as gr\n",
    "import io\n",
    "import random\n",
    "import cloudinary\n",
    "import cloudinary.uploader\n",
    "import cloudinary.api\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Initialize PaddleOCR and Cohere Client\n",
    "paddle_ocr = PaddleOCR()\n",
    "\n",
    "# Fetch Cohere API key\n",
    "api_key = \"RNBdYl0xs4qbwGUnDhkN7ANfm5aF5mAocIOqyauJ\"  # Replace with your actual API key\n",
    "if not api_key:\n",
    "    raise ValueError(\"Cohere API key not provided.\")\n",
    "co = cohere.Client(api_key)\n",
    "\n",
    "# Configure Cloudinary account\n",
    "cloudinary.config(\n",
    "    cloud_name=\"dnxztp85y\",  # Replace with your Cloudinary cloud name\n",
    "    api_key=\"717237922497848\",        # Replace with your Cloudinary API key\n",
    "    api_secret=\"KbdS9kqvrOi925rm3af_NB-yKHM\"   # Replace with your Cloudinary API secret\n",
    ")\n",
    "\n",
    "def download_image_from_url(url):\n",
    "    \"\"\"Download image from URL and return as PIL Image object\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        return Image.open(BytesIO(response.content))\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading image from {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def fetch_from_cloudinary(folder_prefix):\n",
    "    \"\"\"Fetch image URLs from Cloudinary based on folder name\"\"\"\n",
    "    try:\n",
    "        response = cloudinary.api.resources(\n",
    "            type=\"upload\",\n",
    "            prefix=folder_prefix,\n",
    "            resource_type=\"image\",\n",
    "            max_results=100\n",
    "        )\n",
    "        return [resource[\"secure_url\"] for resource in response.get(\"resources\", [])]\n",
    "    except Exception as e:\n",
    "        return f\"Failed to fetch files from Cloudinary: {e}\"\n",
    "\n",
    "def process_documents(document_type, image_sources, is_url=False):\n",
    "    \"\"\"Process documents from either uploaded files or URLs\"\"\"\n",
    "    extracted_data = []\n",
    "    for source in image_sources:\n",
    "        try:\n",
    "            # Handle both uploaded files and URLs\n",
    "            if is_url:\n",
    "                image = download_image_from_url(source)\n",
    "                if image is None:\n",
    "                    continue\n",
    "            else:\n",
    "                image = Image.open(source)\n",
    "\n",
    "            # Convert PIL Image to CV2 format\n",
    "            image_cv2 = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # Perform OCR\n",
    "            paddle_results = paddle_ocr.ocr(image_cv2)\n",
    "\n",
    "            # Extract text from OCR results\n",
    "            if paddle_results and paddle_results[0]:\n",
    "                texts = [line[1][0] for line in paddle_results[0]]\n",
    "                extracted_text = \" \".join(texts)\n",
    "\n",
    "                # Generate prompt based on document type\n",
    "                prompt = f\"Extract the following information from the text: {extracted_text}\\n\\n\"\n",
    "                if document_type == \"Salary Slip\":\n",
    "                    prompt += \"Find and return the values for: Net Salary, Gross Salary, Basic Salary.\"\n",
    "                elif document_type == \"Profit and Loss Statement\":\n",
    "                    prompt += \"Find and return the values for: Total Revenue, Net Income.\"\n",
    "                elif document_type == \"Check\":\n",
    "                    prompt += \"Find and return the values for: Account Number, Amount (in Rupees), Bank Name.\"\n",
    "\n",
    "                # Get response from Cohere\n",
    "                response = co.generate(model='command', prompt=prompt, max_tokens=200)\n",
    "                result_text = response.generations[0].text.strip()\n",
    "\n",
    "                # Parse the response into a dictionary\n",
    "                temp_data = {}\n",
    "                for line in result_text.split(\"\\n\"):\n",
    "                    if \":\" in line:\n",
    "                        key, value = line.split(\":\", 1)\n",
    "                        temp_data[key.strip()] = value.strip()\n",
    "                extracted_data.append(temp_data)\n",
    "            else:\n",
    "                extracted_data.append({\"Error\": \"No text detected in image\"})\n",
    "        except Exception as e:\n",
    "            extracted_data.append({\"Error\": f\"Failed to process image: {str(e)}\"})\n",
    "    return extracted_data\n",
    "\n",
    "def visualize_results(document_type, image_sources, plot_type, is_url=False):\n",
    "    \"\"\"Visualize results from processed documents\"\"\"\n",
    "    if not image_sources:\n",
    "        return \"No files provided. Please upload images or fetch from Cloudinary.\", None\n",
    "\n",
    "    extracted_data = process_documents(document_type, image_sources, is_url)\n",
    "    \n",
    "    if not extracted_data:\n",
    "        return \"No data extracted. Please check your input files.\", None\n",
    "\n",
    "    tables_html = \"\"\n",
    "    visualization_images = []\n",
    "\n",
    "    for idx, data in enumerate(extracted_data):\n",
    "        if data:\n",
    "            df = pd.DataFrame(list(data.items()), columns=[\"Field\", \"Value\"])\n",
    "            tables_html += f\"<h4>Extracted Information for Image {idx + 1}</h4>\"\n",
    "            tables_html += df.to_html(index=False, escape=False, border=0)\n",
    "\n",
    "            # Prepare data for visualization for each image separately\n",
    "            flattened_data = {}\n",
    "            for key, value in data.items():\n",
    "                if key != \"Error\":  # Skip error messages\n",
    "                    try:\n",
    "                        numeric_value = float(re.sub(r\"[^\\d.]+\", \"\", value))\n",
    "                        flattened_data[key] = numeric_value\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "            \n",
    "            if flattened_data:  # Create visualization for this specific image\n",
    "                fig, ax = plt.subplots(figsize=(10, 6))\n",
    "                labels = list(flattened_data.keys())\n",
    "                values = list(flattened_data.values())\n",
    "                \n",
    "                if plot_type == \"Bar Plot\":\n",
    "                    ax.bar(labels, values, color=\"skyblue\", edgecolor=\"black\")\n",
    "                    ax.set_title(f\"{document_type} - Image {idx + 1} - Bar Plot\")\n",
    "                    ax.set_ylabel(\"Amount\")\n",
    "                    ax.set_xlabel(\"Fields\")\n",
    "                    plt.xticks(rotation=45, ha=\"right\")\n",
    "                \n",
    "                elif plot_type == \"Pie Chart\":\n",
    "                    ax.pie(values, labels=labels, autopct=\"%1.1f%%\", startangle=140,\n",
    "                           colors=plt.cm.Paired.colors)\n",
    "                    ax.set_title(f\"{document_type} - Image {idx + 1} - Pie Chart\")\n",
    "\n",
    "                # Save plot to buffer \n",
    "                buf = io.BytesIO()\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(buf, format=\"png\")\n",
    "                buf.seek(0)\n",
    "                image = Image.open(buf)\n",
    "                visualization_images.append(image)\n",
    "                \n",
    "            else:  # If no valid data for visualization, append a blank placeholder image \n",
    "                blank_image = Image.new(\"RGB\", (300, 200), color=(255, 255, 255))\n",
    "                visualization_images.append(blank_image)\n",
    "        else:\n",
    "            tables_html += f\"<h4>Image {idx + 1}</h4>\"\n",
    "            tables_html += \"<p>No data extracted from this image.</p>\"\n",
    "            \n",
    "            blank_image = Image.new(\"RGB\", (300, 200), color=(255, 255, 255))\n",
    "            visualization_images.append(blank_image)\n",
    "\n",
    "    return tables_html, visualization_images\n",
    "\n",
    "def process_cloudinary_images(document_type, num_images, plot_type):\n",
    "    \"\"\"Process images fetched from Cloudinary based on document type\"\"\"\n",
    "    folder_mapping = {\n",
    "        \"Profit and Loss Statement\": \"dataset1/profit and loss\",\n",
    "        \"Salary Slip\": \"dataset1/salary slip\"\n",
    "    }\n",
    "\n",
    "    folder_name = folder_mapping.get(document_type)\n",
    "    \n",
    "    if folder_name is None:\n",
    "        return \"Invalid document type selected.\", None, None\n",
    "\n",
    "    urls = fetch_from_cloudinary(folder_name)  # Pass the correct folder name here\n",
    "    \n",
    "    if isinstance(urls, str):  # Error message \n",
    "        return urls, None, None\n",
    "    \n",
    "    selected_urls = random.sample(urls, min(len(urls), int(num_images)))\n",
    "    \n",
    "    gallery_images = [download_image_from_url(url) for url in selected_urls]\n",
    "    gallery_images = [np.array(img) for img in gallery_images if img is not None]\n",
    "\n",
    "    tables_html, visualization_images = visualize_results(document_type, selected_urls, plot_type, is_url=True)\n",
    "\n",
    "    return tables_html, visualization_images, gallery_images\n",
    "\n",
    "def launch_ui():\n",
    "    \"\"\"Launch the Gradio UI\"\"\"\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"# Document OCR, Analysis, and Visualization\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            document_type = gr.Radio(\n",
    "                [\"Salary Slip\", \"Profit and Loss Statement\", \"Check\"],\n",
    "                label=\"Select Document Type\",\n",
    "            )\n",
    "            plot_type = gr.Radio([\"Bar Plot\", \"Pie Chart\"], label=\"Select Plot Type\")\n",
    "\n",
    "        with gr.Tabs():\n",
    "            with gr.TabItem(\"Upload Files\"):\n",
    "                uploaded_files = gr.File(file_types=[\"image\"], file_count=\"multiple\", label=\"Upload Document Images\")\n",
    "                upload_submit = gr.Button(\"Process Uploaded Files\")\n",
    "\n",
    "            with gr.TabItem(\"Cloudinary Images\"):\n",
    "                num_images = gr.Number(label=\"Number of Random Images from Cloudinary\", value=1)\n",
    "                fetch_button = gr.Button(\"Fetch and Process Cloudinary Images\")\n",
    "                \n",
    "                cloudinary_gallery = gr.Gallery(label=\"Fetched Images from Cloudinary\")\n",
    "                \n",
    "                result = gr.HTML(label=\"Extracted Information\")\n",
    "                \n",
    "                visualization_output = gr.Gallery(label=\"Visualizations\")  # Updated to display multiple visualizations\n",
    "\n",
    "        def process_uploaded_images(document_type, uploaded_files, plot_type):\n",
    "            image_sources = [file.name for file in uploaded_files]  # Convert to list of filenames \n",
    "            tables_html, visualization_images = visualize_results(document_type, image_sources, plot_type)\n",
    "            return tables_html, visualization_images\n",
    "        \n",
    "        upload_submit.click(\n",
    "            process_uploaded_images,\n",
    "            inputs=[document_type, uploaded_files, plot_type],\n",
    "            outputs=[result, visualization_output]\n",
    "        )\n",
    "\n",
    "        fetch_button.click(\n",
    "            process_cloudinary_images,\n",
    "            inputs=[document_type, num_images, plot_type],\n",
    "            outputs=[result, visualization_output, cloudinary_gallery]\n",
    "        )\n",
    "\n",
    "    demo.launch()  # Run the pipeline\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    launch_ui()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e2935a-ff12-46f0-b24f-2e4816cf3c07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
